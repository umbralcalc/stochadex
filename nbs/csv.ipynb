{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples with CSV files\n",
    "\n",
    "> **These are Go notebooks**: In order to use the GoNB Jupyter Kernel, please install GoNB from here: [https://github.com/janpfeifer/gonb](https://github.com/janpfeifer/gonb)\n",
    "\n",
    "Note also that for local package development, you can put: `!*go mod edit -replace \"github.com/umbralcalc/stochadex=/path/to/stochadex\"` at the top of any cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To CSV\n",
    "\n",
    "Writing some stored data of a partition to CSV can be done by first converting to a `gota` dataframe and then calling its CSV writer method. Here's a simple example below using generated data from a Normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\"os\"\n",
    "\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/simulator\"\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/analysis\"\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/inference\"\n",
    ")\n",
    "\n",
    "%%\n",
    "\n",
    "// Create a simulator.StateTimeStorage from a simulation run\n",
    "storage := analysis.NewStateTimeStorageFromPartitions(\n",
    "\t// Instantiate the desired simulation state partitions\n",
    "\t[]*simulator.PartitionConfig{\n",
    "\t\t{\n",
    "\t\t\tName:              \"generated_data\",\n",
    "\t\t\tIteration:         &inference.DataGenerationIteration{\n",
    "\t\t\t\tLikelihood: &inference.NormalLikelihoodDistribution{},\n",
    "\t\t\t},\n",
    "\t\t\tParams:            simulator.NewParams(map[string][]float64{\n",
    "\t\t\t\t\"mean\": {1.8, 5.0, -7.3, 2.2},\n",
    "                \"covariance_matrix\": {2.5, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.4, 0.0, 0.0, 0.0, 0.0, 17.0},\n",
    "\t\t\t}),\n",
    "\t\t\tInitStateValues:   []float64{1.3, 8.3, -4.9, 1.6},\n",
    "\t\t\tStateHistoryDepth: 1,\n",
    "\t\t\tSeed:              1234567,\n",
    "\t\t},\n",
    "    },\n",
    "\t// Decide when should we stop the simulation\n",
    "\t&simulator.NumberOfStepsTerminationCondition{\n",
    "\t\tMaxNumberOfSteps: 1000,\n",
    "\t},\n",
    "\t// Decide how time should evolve\n",
    "\t&simulator.ConstantTimestepFunction{\n",
    "\t\tStepsize: 1.0,\n",
    "\t},\n",
    "\t// Input the initial time\n",
    "\t0.0,\n",
    ")\n",
    "\n",
    "// Retrieve a dataframe representing the data in one partition\n",
    "df := analysis.GetDataFrameFromPartition(storage, \"generated_data\")\n",
    "\n",
    "// Save the dataframe as a CSV for later\n",
    "file, _ := os.Create(\"data/test_csv.csv\")\n",
    "df.WriteCSV(file)\n",
    "\n",
    "// Display the dataframe\n",
    "fmt.Println(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From CSV\n",
    "\n",
    "We can also read CSV data into storage by using a function in the analysis package. The example below does this, where we have used the CSV data written to a file above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/simulator\"\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/analysis\"\n",
    "\t\n",
    "\tgonb_echarts \"github.com/janpfeifer/gonb-echarts\"\n",
    ")\n",
    "\n",
    "%%\n",
    "\n",
    "// Read in CSV data directly into a simulator.StateTimeStorage\n",
    "storage, _ := analysis.NewStateTimeStorageFromCsv(\n",
    "\t\"data/test_csv.csv\",\n",
    "\t0,\n",
    "\tmap[string][]int{\"generated_data\" : {1, 2, 3, 4}},\n",
    "\ttrue,\n",
    ")\n",
    "\n",
    "// Reference the plotting data for the x-axis\n",
    "xRef := analysis.DataRef{Plotting: &analysis.DataPlotting{IsTime: true}}\n",
    "\n",
    "// Reference the plotting data for the y-axis\n",
    "yRefs := []analysis.DataRef{{PartitionName: \"generated_data\"}}\n",
    "\n",
    "// Create a scatter plot from partitions in a simulator.StateTimeStorage\n",
    "scatter := analysis.NewScatterPlotFromPartition(storage, xRef, yRefs)\n",
    "\n",
    "// Display the plot in a Go notebook\n",
    "gonb_echarts.Display(scatter, \"width: 1024px; height:400px; background: white;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood comparison\n",
    "\n",
    "We can configure rolling windowed likelihood comparisons with relatively few steps using the functions provided in the analysis package. In the example below, we create such a comparison between the data read from CSV above and a Normal distribution likelihood model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/kernels\"\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/simulator\"\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/analysis\"\n",
    "\t\n",
    "\tgonb_echarts \"github.com/janpfeifer/gonb-echarts\"\n",
    ")\n",
    "\n",
    "%%\n",
    "\n",
    "// Read in CSV data directly into a simulator.StateTimeStorage\n",
    "storage, _ := analysis.NewStateTimeStorageFromCsv(\n",
    "\t\"data/test_csv.csv\",\n",
    "\t0,\n",
    "\tmap[string][]int{\"generated_data\" : {1, 2, 3, 4}},\n",
    "\ttrue,\n",
    ")\n",
    "\n",
    "// Configure a partition for computing the exponentially-weighted rolling mean\n",
    "meanPartition := analysis.NewVectorMeanPartition(\n",
    "\tanalysis.AppliedAggregation{\n",
    "\t\tName: \"mean\",\n",
    "\t\tData: analysis.DataRef{PartitionName: \"generated_data\"},\n",
    "\t\tKernel: &kernels.ExponentialIntegrationKernel{},\n",
    "\t}, \n",
    "\tstorage,\n",
    ")\n",
    "\n",
    "// Set the timescale for the exponential weighting\n",
    "meanPartition.Params.Set(\"exponential_weighting_timescale\", []float64{100.0})\n",
    "\n",
    "// Run and add the mean partition to storage\n",
    "storage = analysis.AddPartitionsToStateTimeStorage(\n",
    "\tstorage,\n",
    "\t[]*simulator.PartitionConfig{meanPartition},\n",
    "\tmap[string]int{\"generated_data\": 200},\n",
    ")\n",
    "\n",
    "// Configure a partition for computing the exponentially-weighted rolling variance\n",
    "variancePartition := analysis.NewVectorVariancePartition(\n",
    "\tanalysis.DataRef{PartitionName: \"mean\"},\n",
    "\tanalysis.AppliedAggregation{\n",
    "\t\tName: \"variance\",\n",
    "\t\tData: analysis.DataRef{PartitionName: \"generated_data\"},\n",
    "\t\tKernel: &kernels.ExponentialIntegrationKernel{},\n",
    "\t\tDefaultValue: 1.0,\n",
    "\t},\n",
    "\tstorage,\n",
    ")\n",
    "\n",
    "// Set the timescale for the exponential weighting\n",
    "variancePartition.Params.Set(\"exponential_weighting_timescale\", []float64{100.0})\n",
    "\n",
    "// Run and add the variance partition to storage\n",
    "storage = analysis.AddPartitionsToStateTimeStorage(\n",
    "\tstorage,\n",
    "\t[]*simulator.PartitionConfig{variancePartition},\n",
    "\tmap[string]int{\"mean\": 1, \"generated_data\": 200},\n",
    ")\n",
    "\n",
    "// Configure a model where the mean and variance are updated by the rolling estimators\n",
    "model := analysis.ParameterisedModel{\n",
    "\tLikelihood: &inference.NormalLikelihoodDistribution{},\n",
    "\tParams: simulator.NewParams(make(map[string][]float64)),\n",
    "\tParamsFromUpstream: map[string]simulator.NamedUpstreamConfig{\n",
    "\t\t\"mean\": {Upstream: \"mean\"},\n",
    "\t\t\"variance\": {Upstream: \"variance\"},\n",
    "\t},\n",
    "}\n",
    "\n",
    "// Configure a partition for computing the rolling likelihood comparison against the data\n",
    "comparisonPartition := analysis.NewLikelihoodComparisonPartition(\n",
    "\tanalysis.AppliedLikelihoodComparison{\n",
    "\t\tName:  \"loglikelihood\",\n",
    "\t\tModel: model,\n",
    "\t\tData:  analysis.DataRef{PartitionName: \"generated_data\"},\n",
    "\t\tWindow: analysis.WindowedPartitions{\n",
    "\t\t\tData: []analysis.DataRef{\n",
    "\t\t\t\t{PartitionName: \"generated_data\"},\n",
    "\t\t\t\t{PartitionName: \"mean\"},\n",
    "\t\t\t\t{PartitionName: \"variance\"},\n",
    "\t\t\t},\n",
    "\t\t\tDepth: 200,\n",
    "\t\t},\n",
    "\t},\n",
    "\tstorage,\n",
    ")\n",
    "\n",
    "// Run and add the likelihood comparison partition to storage\n",
    "storage = analysis.AddPartitionsToStateTimeStorage(\n",
    "\tstorage,\n",
    "\t[]*simulator.PartitionConfig{comparisonPartition},\n",
    "\tmap[string]int{\"mean\": 200, \"variance\": 200, \"generated_data\": 200},\n",
    ")\n",
    "\n",
    "// Reference the plotting data for the x-axis\n",
    "xRef := analysis.DataRef{\n",
    "\tPlotting: &analysis.DataPlotting{\n",
    "\t\tIsTime: true,\n",
    "\t\tTimeRange: &analysis.IndexRange{Lower: 200, Upper: 1000},\n",
    "\t},\n",
    "}\n",
    "\n",
    "// Reference the plotting data for the y-axis\n",
    "yRefs := []analysis.DataRef{{\n",
    "\tPartitionName: \"loglikelihood\",\n",
    "\tValueIndices: []int{12},\n",
    "\tPlotting: &analysis.DataPlotting{\n",
    "\t\tTimeRange: &analysis.IndexRange{Lower: 200, Upper: 1000},\n",
    "\t},\n",
    "}}\n",
    "\n",
    "// Create a line plot from partitions in a simulator.StateTimeStorage\n",
    "line := analysis.NewLinePlotFromPartition(storage, xRef, yRefs, nil)\n",
    "\n",
    "// Display the plot in a Go notebook\n",
    "gonb_echarts.Display(line, \"width: 1024px; height:400px; background: white;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation inference\n",
    "\n",
    "We can also configure a posterior estimation and sampling of simulation parameters given the rolling data models provided for likelihood comparison. In the example below, we do this to estimate the mean vector of the normal distribution for the data we wrote to CSV above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/kernels\"\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/simulator\"\n",
    "\t\"github.com/umbralcalc/stochadex/pkg/analysis\"\n",
    "\t\n",
    "\tgonb_echarts \"github.com/janpfeifer/gonb-echarts\"\n",
    ")\n",
    "\n",
    "%%\n",
    "\n",
    "// Read in CSV data directly into a simulator.StateTimeStorage\n",
    "storage, _ := analysis.NewStateTimeStorageFromCsv(\n",
    "\t\"data/test_csv.csv\",\n",
    "\t0,\n",
    "\tmap[string][]int{\"generated_data\" : {1, 2, 3, 4}},\n",
    "\ttrue,\n",
    ")\n",
    "\n",
    "// Configure a partition for computing the exponentially-weighted rolling mean\n",
    "meanPartition := analysis.NewVectorMeanPartition(\n",
    "\tanalysis.AppliedAggregation{\n",
    "\t\tName: \"mean\",\n",
    "\t\tData: analysis.DataRef{PartitionName: \"generated_data\"},\n",
    "\t\tKernel: &kernels.ConstantIntegrationKernel{},\n",
    "\t}, \n",
    "\tstorage,\n",
    ")\n",
    "\n",
    "// Set the timescale for the exponential weighting\n",
    "meanPartition.Params.Set(\"exponential_weighting_timescale\", []float64{100.0})\n",
    "\n",
    "// Run and add the mean partition to storage\n",
    "storage = analysis.AddPartitionsToStateTimeStorage(\n",
    "\tstorage,\n",
    "\t[]*simulator.PartitionConfig{meanPartition},\n",
    "\tmap[string]int{\"generated_data\": 200},\n",
    ")\n",
    "\n",
    "// Configure a partition for computing the exponentially-weighted rolling variance\n",
    "variancePartition := analysis.NewVectorVariancePartition(\n",
    "\tanalysis.DataRef{PartitionName: \"mean\"},\n",
    "\tanalysis.AppliedAggregation{\n",
    "\t\tName: \"variance\",\n",
    "\t\tData: analysis.DataRef{PartitionName: \"generated_data\"},\n",
    "\t\tKernel: &kernels.ConstantIntegrationKernel{},\n",
    "\t\tDefaultValue: 1.0,\n",
    "\t},\n",
    "\tstorage,\n",
    ")\n",
    "\n",
    "// Set the timescale for the exponential weighting\n",
    "variancePartition.Params.Set(\"exponential_weighting_timescale\", []float64{100.0})\n",
    "\n",
    "// Run and add the variance partition to storage\n",
    "storage = analysis.AddPartitionsToStateTimeStorage(\n",
    "\tstorage,\n",
    "\t[]*simulator.PartitionConfig{variancePartition},\n",
    "\tmap[string]int{\"mean\": 1, \"generated_data\": 200},\n",
    ")\n",
    "\n",
    "// Configure a model where the mean and variance are updated by the rolling estimators\n",
    "model := analysis.ParameterisedModel{\n",
    "\tLikelihood: &inference.NormalLikelihoodDistribution{},\n",
    "\tParams: simulator.NewParams(make(map[string][]float64)),\n",
    "\tParamsFromUpstream: map[string]simulator.NamedUpstreamConfig{\n",
    "\t\t\"mean\": {Upstream: \"mean\"},\n",
    "\t\t\"variance\": {Upstream: \"variance\"},\n",
    "\t},\n",
    "}\n",
    "\n",
    "// Configure a 'simulation' to infer the posterior samples of target parameters\n",
    "simulation := &simulator.PartitionConfig{\n",
    "\tName:              \"regenerated_data\",\n",
    "\tIteration:         &inference.DataGenerationIteration{\n",
    "\t\tLikelihood: &inference.NormalLikelihoodDistribution{},\n",
    "\t},\n",
    "\tParams:             simulator.NewParams(map[string][]float64{\n",
    "\t\t\"covariance_matrix\": {2.5, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.4, 0.0, 0.0, 0.0, 0.0, 17.0},\n",
    "\t}),\n",
    "\tInitStateValues:    []float64{0.0, 0.0, 0.0, 0.0},\n",
    "\tStateHistoryDepth:  1,\n",
    "\tSeed:               123,\n",
    "}\n",
    "\n",
    "// Configure some partitions which collectively estimate and sample from the posterior\n",
    "// distribution over the target parameters (the rolling mean vector in this example)\n",
    "partitions := analysis.NewPosteriorEstimationPartitions(\n",
    "\tanalysis.AppliedPosteriorEstimation{\n",
    "\t\tNames: analysis.PosteriorEstimationNames{\n",
    "\t\t\tLogNorm:    \"posterior_log_norm\",\n",
    "\t\t\tMean:       \"posterior_mean\",\n",
    "\t\t\tCovariance: \"posterior_cov\",\n",
    "\t\t\tSampler:    \"posterior_sampler\",\n",
    "\t\t},\n",
    "\t\tComparison: analysis.AppliedLikelihoodComparison{\n",
    "\t\t\tName:  \"loglikelihood\",\n",
    "\t\t\tModel: model,\n",
    "\t\t\tData:  analysis.DataRef{PartitionName: \"regenerated_data\"},\n",
    "\t\t\tWindow: analysis.WindowedPartitions{\n",
    "\t\t\t\tPartitions: []analysis.WindowedPartition{{\n",
    "\t\t\t\t\tPartition: simulation,\n",
    "\t\t\t\t\tOutsideUpstreams: map[string]simulator.NamedUpstreamConfig{\n",
    "\t\t\t\t\t\t\"mean\": {Upstream: \"posterior_sampler\"},\n",
    "\t\t\t\t\t}, \n",
    "\t\t\t\t}},\n",
    "\t\t\t\tData: []analysis.DataRef{\n",
    "\t\t\t\t\t{PartitionName: \"mean\"},\n",
    "\t\t\t\t\t{PartitionName: \"variance\"},\n",
    "\t\t\t\t},\n",
    "\t\t\t\tDepth: 200,\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\tDefaults: analysis.PosteriorDefaults{\n",
    "\t\t\tLogNorm:    0.0,\n",
    "\t\t\tMean:       []float64{0.0, 0.0, 0.0, 0.0},\n",
    "\t\t\tCovariance: []float64{5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0},\n",
    "\t\t\tSampler:    []float64{0.0, 0.0, 0.0, 0.0},\n",
    "\t\t},\n",
    "\t\tPastDiscount: 1.0,\n",
    "        MemoryDepth:  300,\n",
    "\t\tSeed:         1234,\n",
    "\t},\n",
    "\tstorage,\n",
    ")\n",
    "\n",
    "// Run and add the likelihood comparison partition to storage\n",
    "storage = analysis.AddPartitionsToStateTimeStorage(\n",
    "\tstorage,\n",
    "\tpartitions,\n",
    "\tmap[string]int{\"mean\": 200, \"variance\": 200},\n",
    ")\n",
    "\n",
    "// Reference the plotting data for the x-axis\n",
    "xRef := analysis.DataRef{Plotting: &analysis.DataPlotting{IsTime: true}}\n",
    "\n",
    "// Reference the likelihood partition plotting data for the y-axis\n",
    "yRefs := []analysis.DataRef{{\n",
    "\tPartitionName: \"loglikelihood\",\n",
    "\tValueIndices: []int{12},\n",
    "}}\n",
    "\n",
    "// Create a line plot from partitions in a simulator.StateTimeStorage\n",
    "line := analysis.NewLinePlotFromPartition(storage, xRef, yRefs, nil)\n",
    "\n",
    "// Display the plot in a Go notebook\n",
    "gonb_echarts.Display(line, \"width: 1024px; height:400px; background: white;\")\n",
    "\n",
    "// Reference the posterior samples plotting data for the y-axis\n",
    "yRefs = []analysis.DataRef{{PartitionName: \"posterior_sampler\"}}\n",
    "\n",
    "// Create a scatter plot from partitions in a simulator.StateTimeStorage\n",
    "scatter := analysis.NewScatterPlotFromPartition(storage, xRef, yRefs)\n",
    "\n",
    "// Display the plot in a Go notebook\n",
    "gonb_echarts.Display(scatter, \"width: 1024px; height:400px; background: white;\")\n",
    "\n",
    "// Reference the rolling mean plotting data (the target params) for the y-axis\n",
    "yRefs = []analysis.DataRef{{PartitionName: \"mean\"}}\n",
    "\n",
    "// Create a line plot from partitions in a simulator.StateTimeStorage\n",
    "line = analysis.NewLinePlotFromPartition(storage, xRef, yRefs, nil)\n",
    "\n",
    "// Display the plot in a Go notebook\n",
    "gonb_echarts.Display(line, \"width: 1024px; height:400px; background: white;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.23.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
